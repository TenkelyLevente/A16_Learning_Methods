# -*- coding: utf-8 -*-
"""REGRESSION

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Jdh9dkht1rFMDxRgJ6eK1080r2CgtgE

# **Adatok betöltése és könyvtárak importálása**
"""

pip install pygad

pip install evolutionary-keras

# Könyvtárak importálása
import matplotlib.pyplot as plt
import tensorflow as tf
import keras
import numpy as np
from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report, confusion_matrix
import datetime
import pygad
import seaborn as sn
import pandas as pd
import random, time
import pygad.kerasga
import tensorflow
import matplotlib.pyplot as plt
import tensorflow as tf
import keras
import numpy as np
from tensorflow.keras import Sequential, layers, models, datasets
from keras.layers import Dense, Conv2D , MaxPool2D , Flatten ,Input
import sys
from tensorflow.keras import backend as K
from evolutionary_keras.models import EvolModel
import evolutionary_keras.optimizers
from tensorflow.keras.models import Model
import logging
logging.basicConfig(level = logging.INFO)
logger = logging.getLogger()
from sklearn.datasets import load_iris

"""# **Tanító és validációs adatgyűjtemények létrehozása**"""

url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'
column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',
                'Acceleration', 'Model Year', 'Origin']

raw_dataset = pd.read_csv(url, names=column_names,
                          na_values='?', comment='\t',
                          sep=' ', skipinitialspace=True)
dataset = raw_dataset.copy()
dataset.tail()
dataset = dataset.dropna()
dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})
dataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')
dataset.tail()
train_dataset = dataset.sample(frac=0.8, random_state=0)
test_dataset = dataset.drop(train_dataset.index)
train_dataset.describe().transpose()

train_features = train_dataset.copy()
test_features = test_dataset.copy()

train_labels = train_features.pop('MPG')
test_labels = test_features.pop('MPG')

def build_and_compile_model():
  model = keras.Sequential([
      layers.Input(shape=(9)),
      layers.Dense(16, activation='relu'),
      layers.Dense(16, activation='relu'),
      layers.Dense(1)
  ])

  #model.compile(loss='mean_absolute_error',
  #              optimizer=tf.keras.optimizers.Adam(0.001))
  return model
model=build_and_compile_model()
modelGD=build_and_compile_model()

inputs=Input(shape=(9))
dense_1=layers.Dense(16, activation='relu')(inputs)
dense_2=layers.Dense(16, activation='relu')(dense_1)
prediction=layers.Dense(1)(dense_2)

modelEvol = EvolModel(inputs=inputs, outputs=prediction)

"""# GD"""

modelGD.compile(loss='mean_absolute_error',
                optimizer=tf.keras.optimizers.Adam(0.001))
historyGD = modelGD.fit(
    train_features, train_labels,
    validation_split=0.2,
    verbose=1, epochs=200)

scoreGD = modelGD.evaluate(x=test_features, y=test_labels, return_dict=True, verbose=0)
print("Test loss:", scoreGD['loss'])

"""# PyGAD"""

def fitness_func(solution, sol_idx):
    global data_inputs, data_outputs, keras_ga, model

    model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model=model,
                                                                 weights_vector=solution)

    model.set_weights(weights=model_weights_matrix)

    predictions = model.predict(data_inputs)
    mae = tensorflow.keras.losses.MeanAbsoluteError()
    abs_error = mae(data_outputs, predictions).numpy() + 0.00000001
    solution_fitness = 1.0/abs_error

    return solution_fitness

def callback_generation(ga_instance):
    print("Generation = {generation}".format(generation=ga_instance.generations_completed))
    print("Fitness    = {fitness}".format(fitness=ga_instance.best_solution()[1]))

# Create an instance of the pygad.kerasga.KerasGA class to build the initial population.
keras_ga = pygad.kerasga.KerasGA(model=model,
                                 num_solutions=100)

# Data inputs
data_inputs = train_features#numpy.load("dataset_inputs.npy")

# Data outputs
data_outputs = train_labels#numpy.load("dataset_outputs.npy")
#data_outputs = tensorflow.keras.utils.to_categorical(data_outputs)

# Prepare the PyGAD parameters. Check the documentation for more information: https://pygad.readthedocs.io/en/latest/README_pygad_ReadTheDocs.html#pygad-ga-class
num_generations = 300 # Number of generations.
num_parents_mating = 30 # Number of solutions to be selected as parents in the mating pool.
initial_population = keras_ga.population_weights # Initial population of network weights
parent_selection_type = "sss" # Type of parent selection.
crossover_type = "two_points" # Type of the crossover operator.
mutation_type = "random" # Type of the mutation operator.
mutation_percent_genes = 10 # Percentage of genes to mutate. This parameter has no action if the parameter mutation_num_genes exists.
keep_parents = 1 # Number of parents to keep in the next population. -1 means keep all parents and 0 means keep nothing.

ga_instance = pygad.GA(num_generations=num_generations,
                       num_parents_mating=num_parents_mating,
                       initial_population=initial_population,
                       fitness_func=fitness_func,
                       parent_selection_type=parent_selection_type,
                       crossover_type=crossover_type,
                       mutation_type=mutation_type,
                       mutation_percent_genes=mutation_percent_genes,
                       keep_parents=keep_parents,
                       on_generation=callback_generation)

# Start the genetic algorithm evolution.
ga_instance.run()

# After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.
ga_instance.plot_result(title="PyGAD & Keras - Iteration vs. Fitness", linewidth=4)

# Returning the details of the best solution.
solution, solution_fitness, solution_idx = ga_instance.best_solution()
print("Fitness value of the best solution = {solution_fitness}".format(solution_fitness=solution_fitness))
print("Index of the best solution : {solution_idx}".format(solution_idx=solution_idx))

# Fetch the parameters of the best solution.
best_solution_weights = pygad.kerasga.model_weights_as_matrix(model=model,
                                                              weights_vector=solution)
model.set_weights(best_solution_weights)
predictions = model.predict(data_inputs)
print("Predictions : \n", predictions)

mae = tensorflow.keras.losses.MeanAbsoluteError()
abs_error = mae(data_outputs, predictions).numpy()
print("Absolute Error : ", abs_error)

"""# CMA"""

inputs=Input(shape=(9))
dense_1=layers.Dense(16, activation='relu')(inputs)
dense_2=layers.Dense(16, activation='relu')(dense_1)
prediction=layers.Dense(1)(dense_2)

modelEvol = EvolModel(inputs=inputs, outputs=prediction)

myopt = evolutionary_keras.optimizers.CMA(population_size=5, sigma_init=15,max_evaluations=1500)
modelEvol.compile(optimizer=myopt, loss="mean_absolute_error", metrics=["accuracy"])
modelEvol.summary()

historyCMA = modelEvol.fit(
    x=train_features,
    y=train_labels,
    epochs=1,
    verbose=1,
    #validation_data=(x_test, y_test)
)

scoreCMA = modelEvol.evaluate(x=test_features, y=test_labels, return_dict=True, verbose=0)
print("Test loss:", scoreCMA['loss'])

"""# NGA"""

inputs=Input(shape=(9))
dense_1=layers.Dense(16, activation='relu')(inputs)
dense_2=layers.Dense(16, activation='relu')(dense_1)
prediction=layers.Dense(1)(dense_2)

modelEvol = EvolModel(inputs=inputs, outputs=prediction)

#NGA
myopt = evolutionary_keras.optimizers.NGA(population_size=5, sigma_init=15)
modelEvol.compile(optimizer=myopt, loss="mean_absolute_error", metrics=["accuracy"])

historyNGA = modelEvol.fit(
    train_features,
    train_labels,
    verbose=1,
    epochs=500
    #validation_data=(x_test, y_test)
)

scoreNGA= modelEvol.evaluate(x=test_features, y=test_labels, return_dict=True, verbose=0)
print("Test loss:", scoreNGA['loss'])

plt.figure(figsize=(5,5))
plt.plot(range(len(historyGD.history['loss'])), historyGD.history['loss'], label='Gradient Descent')
plt.plot(range(len(historyNGA.history['loss'])), historyNGA.history['loss'],label='NGA')


plt.legend()
plt.xlabel('Epoch')
plt.ylabel('Loss')