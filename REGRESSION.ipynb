{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "REGRESSION",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wD3vraPV0av"
      },
      "source": [
        "# **Adatok betöltése és könyvtárak importálása**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv-JQPc521Ng",
        "outputId": "2278a521-310a-4e8c-c52b-48130fa2910f"
      },
      "source": [
        "pip install pygad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygad\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/36/e36a9f2b4360d5464da73cea4886d3230878c9d7d2650907dc8ad4cb49cc/pygad-2.13.0-py3-none-any.whl (45kB)\n",
            "\r\u001b[K     |███████▏                        | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 20kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 30kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 40kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pygad) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pygad) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->pygad) (1.15.0)\n",
            "Installing collected packages: pygad\n",
            "Successfully installed pygad-2.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKaGIVTaQw0_",
        "outputId": "4f9f46c4-e257-426e-88aa-52e34befe2b6"
      },
      "source": [
        " pip install evolutionary-keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting evolutionary-keras\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/58/f0af58ee8a3571395eb25baa1b4c421e9b82d8918031ccae5b78cc6ab31c/evolutionary_keras-2.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from evolutionary-keras) (1.19.5)\n",
            "Collecting cma\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/c0/0a1c41f7cad0a51e07991cf86423d0e6651d035f1fe7dcff48e8858848f2/cma-3.0.3-py2.py3-none-any.whl (230kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 20.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 26.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 31.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 25.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 61kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 11.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 81kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 92kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 102kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 112kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 122kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 133kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 143kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 153kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 163kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 174kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 184kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 194kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 204kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 215kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 225kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 13.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>2.1* in /usr/local/lib/python3.7/dist-packages (from evolutionary-keras) (2.4.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (0.12.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (1.12)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (1.32.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (2.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>2.1*->evolutionary-keras) (1.6.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (56.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (1.28.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (3.3.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (3.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>2.1*->evolutionary-keras) (3.4.1)\n",
            "Installing collected packages: cma, evolutionary-keras\n",
            "Successfully installed cma-3.0.3 evolutionary-keras-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7r02xWiWWsy"
      },
      "source": [
        "# Könyvtárak importálása\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import datetime\n",
        "import pygad\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import random, time\n",
        "import pygad.kerasga\n",
        "import tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential, layers, models, datasets\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten ,Input\n",
        "import sys\n",
        "from tensorflow.keras import backend as K\n",
        "from evolutionary_keras.models import EvolModel\n",
        "import evolutionary_keras.optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "import logging\n",
        "logging.basicConfig(level = logging.INFO)\n",
        "logger = logging.getLogger()\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiPieu7Hd6tu"
      },
      "source": [
        "# **Tanító és validációs adatgyűjtemények létrehozása**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP2tLOffBEOU"
      },
      "source": [
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "raw_dataset = pd.read_csv(url, names=column_names,\n",
        "                          na_values='?', comment='\\t',\n",
        "                          sep=' ', skipinitialspace=True)\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()\n",
        "dataset = dataset.dropna()\n",
        "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
        "dataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\n",
        "dataset.tail()\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "train_dataset.describe().transpose()\n",
        "\n",
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "train_labels = train_features.pop('MPG')\n",
        "test_labels = test_features.pop('MPG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loG1Ykg3DmT-"
      },
      "source": [
        "def build_and_compile_model():\n",
        "  model = keras.Sequential([\n",
        "      layers.Input(shape=(9)),\n",
        "      layers.Dense(16, activation='relu'),\n",
        "      layers.Dense(16, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  #model.compile(loss='mean_absolute_error',\n",
        "  #              optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model\n",
        "model=build_and_compile_model()\n",
        "modelGD=build_and_compile_model()\n",
        "\n",
        "inputs=Input(shape=(9))\n",
        "dense_1=layers.Dense(16, activation='relu')(inputs)\n",
        "dense_2=layers.Dense(16, activation='relu')(dense_1)\n",
        "prediction=layers.Dense(1)(dense_2)\n",
        "\n",
        "modelEvol = EvolModel(inputs=inputs, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6poUgKzOZUs"
      },
      "source": [
        "# GD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkglKW0QNPSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb2256d-c1d1-4a35-9818-2c3029c12778"
      },
      "source": [
        "modelGD.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "historyGD = modelGD.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=1, epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 3s 30ms/step - loss: 90.1197 - val_loss: 56.4357\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 41.0139 - val_loss: 37.1615\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 27.2089 - val_loss: 29.8704\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 23.8318 - val_loss: 24.7275\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 21.5367 - val_loss: 24.0223\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 18.3876 - val_loss: 22.1537\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 18.8421 - val_loss: 20.9510\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 19.2652 - val_loss: 21.1160\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 17.0869 - val_loss: 19.1894\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 15.7697 - val_loss: 18.9214\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 15.1595 - val_loss: 17.4811\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 15.7359 - val_loss: 16.6410\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.4469 - val_loss: 16.5026\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 13.6718 - val_loss: 14.7483\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 12.1162 - val_loss: 13.8256\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.1722 - val_loss: 13.2533\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.9157 - val_loss: 14.6503\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.1833 - val_loss: 12.4557\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.0301 - val_loss: 12.0520\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.0457 - val_loss: 14.0576\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.7614 - val_loss: 15.3383\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11.3742 - val_loss: 11.9354\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.7617 - val_loss: 11.1505\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.1135 - val_loss: 11.8488\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.1260 - val_loss: 7.8030\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5701 - val_loss: 8.1677\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.7136 - val_loss: 6.6238\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9265 - val_loss: 7.1793\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7108 - val_loss: 6.3195\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.4970 - val_loss: 6.4206\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.3958 - val_loss: 5.4630\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4310 - val_loss: 5.7017\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2566 - val_loss: 5.9552\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.8193 - val_loss: 4.9543\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4701 - val_loss: 5.0260\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1585 - val_loss: 7.5519\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5564 - val_loss: 5.4858\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.7026 - val_loss: 4.2809\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1657 - val_loss: 4.1772\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1711 - val_loss: 4.3479\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8070 - val_loss: 4.1626\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7205 - val_loss: 4.0552\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.2090 - val_loss: 3.8960\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5780 - val_loss: 3.7557\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.9228 - val_loss: 13.0806\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.0383 - val_loss: 3.9087\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9020 - val_loss: 3.5941\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7644 - val_loss: 4.8581\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5326 - val_loss: 5.1318\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0384 - val_loss: 3.6598\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7829 - val_loss: 3.4026\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.8416 - val_loss: 3.4578\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3130 - val_loss: 5.8110\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9207 - val_loss: 4.0560\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5103 - val_loss: 3.5321\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.7487 - val_loss: 3.3254\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2879 - val_loss: 3.3388\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5281 - val_loss: 4.4415\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.2649 - val_loss: 4.1019\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8160 - val_loss: 3.1000\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0860 - val_loss: 4.3216\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.8453 - val_loss: 4.3606\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9352 - val_loss: 3.1281\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9853 - val_loss: 4.6157\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9398 - val_loss: 6.2071\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5629 - val_loss: 4.4491\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1136 - val_loss: 3.2518\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2504 - val_loss: 2.9218\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0657 - val_loss: 3.7122\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3143 - val_loss: 2.9705\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2762 - val_loss: 4.8151\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8582 - val_loss: 4.7024\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7739 - val_loss: 3.7582\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.8065 - val_loss: 3.4999\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3845 - val_loss: 4.7496\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4730 - val_loss: 3.0264\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2353 - val_loss: 4.6160\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.3153 - val_loss: 3.0295\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.2957 - val_loss: 3.0179\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8852 - val_loss: 3.0427\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1948 - val_loss: 3.0735\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1378 - val_loss: 2.9066\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9213 - val_loss: 4.1990\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3418 - val_loss: 2.8884\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1481 - val_loss: 2.7737\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3763 - val_loss: 2.9020\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1499 - val_loss: 3.5994\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2532 - val_loss: 3.0211\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1425 - val_loss: 5.4167\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9697 - val_loss: 4.2699\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5367 - val_loss: 3.7873\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4345 - val_loss: 2.8717\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0898 - val_loss: 3.0036\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3408 - val_loss: 2.9699\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9416 - val_loss: 4.0910\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6425 - val_loss: 3.4612\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0954 - val_loss: 3.3519\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2772 - val_loss: 3.3999\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.2891 - val_loss: 4.9903\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0203 - val_loss: 3.2562\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0838 - val_loss: 2.9352\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0195 - val_loss: 3.8197\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.7327 - val_loss: 3.4589\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1354 - val_loss: 2.7987\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0333 - val_loss: 4.5932\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3069 - val_loss: 2.9909\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8140 - val_loss: 3.0989\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9887 - val_loss: 2.8372\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9690 - val_loss: 3.5986\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5513 - val_loss: 3.4671\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3636 - val_loss: 2.9192\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2304 - val_loss: 3.4174\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2619 - val_loss: 3.8781\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4162 - val_loss: 3.5207\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.0848 - val_loss: 3.4168\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9287 - val_loss: 2.7929\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0343 - val_loss: 3.4276\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4801 - val_loss: 3.1037\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2745 - val_loss: 3.0105\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9873 - val_loss: 3.0492\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1562 - val_loss: 2.7478\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8151 - val_loss: 8.6023\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9245 - val_loss: 3.2594\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7380 - val_loss: 4.6900\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4895 - val_loss: 4.1979\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0726 - val_loss: 5.6319\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4496 - val_loss: 3.2981\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.2366 - val_loss: 2.7945\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3009 - val_loss: 4.0128\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5980 - val_loss: 3.2180\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2837 - val_loss: 2.7263\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9872 - val_loss: 3.8227\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7743 - val_loss: 6.7036\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3831 - val_loss: 3.4391\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.5296 - val_loss: 4.4574\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9286 - val_loss: 2.8854\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3948 - val_loss: 5.3815\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3439 - val_loss: 3.4474\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1755 - val_loss: 3.3721\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6455 - val_loss: 2.7961\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0574 - val_loss: 3.6057\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4708 - val_loss: 3.2611\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6365 - val_loss: 4.9904\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5624 - val_loss: 2.8425\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3843 - val_loss: 3.0182\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.7070 - val_loss: 5.7864\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5696 - val_loss: 6.3271\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0131 - val_loss: 3.8783\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.2325 - val_loss: 2.7177\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9397 - val_loss: 2.7274\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2876 - val_loss: 3.9300\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.5190 - val_loss: 5.6639\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.3757 - val_loss: 2.8294\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9282 - val_loss: 2.7914\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8986 - val_loss: 3.2947\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0354 - val_loss: 2.9487\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9840 - val_loss: 2.7512\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8305 - val_loss: 2.7208\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9988 - val_loss: 4.3686\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0164 - val_loss: 4.7181\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4369 - val_loss: 3.1591\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7818 - val_loss: 2.9122\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8147 - val_loss: 2.9068\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.7862 - val_loss: 2.9149\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7469 - val_loss: 4.2131\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0863 - val_loss: 2.9608\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8840 - val_loss: 3.1337\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.7669 - val_loss: 2.9150\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.8571 - val_loss: 2.7268\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.8699 - val_loss: 2.7800\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8372 - val_loss: 2.7284\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.1739 - val_loss: 4.1150\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2339 - val_loss: 7.0371\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.1510 - val_loss: 4.7559\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.9511 - val_loss: 4.9557\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1449 - val_loss: 3.6175\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6408 - val_loss: 4.1061\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6408 - val_loss: 2.9892\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8496 - val_loss: 2.8277\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9207 - val_loss: 2.6962\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0587 - val_loss: 2.8511\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7976 - val_loss: 2.7588\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9782 - val_loss: 4.1881\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9186 - val_loss: 3.3314\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9475 - val_loss: 3.5991\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.7156 - val_loss: 2.8174\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8792 - val_loss: 2.7839\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9864 - val_loss: 2.8867\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.8751 - val_loss: 2.7472\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1041 - val_loss: 3.0145\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.9695 - val_loss: 3.7640\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.1949 - val_loss: 5.2198\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8834 - val_loss: 2.7030\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.7348 - val_loss: 2.6931\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9709 - val_loss: 3.7310\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3744 - val_loss: 4.1270\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.8328 - val_loss: 2.8799\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2049 - val_loss: 2.7023\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8631 - val_loss: 4.1752\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2840 - val_loss: 3.3770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED8MwfI5RaAk",
        "outputId": "96e2029f-a1b2-4b7f-aa0b-2f893f91e553"
      },
      "source": [
        "scoreGD = modelGD.evaluate(x=test_features, y=test_labels, return_dict=True, verbose=0)\n",
        "print(\"Test loss:\", scoreGD['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.8030052185058594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2COYW8sHMyM5"
      },
      "source": [
        "# PyGAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt87iQpI394r"
      },
      "source": [
        "def fitness_func(solution, sol_idx):\n",
        "    global data_inputs, data_outputs, keras_ga, model\n",
        "\n",
        "    model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model=model,\n",
        "                                                                 weights_vector=solution)\n",
        "\n",
        "    model.set_weights(weights=model_weights_matrix)\n",
        "\n",
        "    predictions = model.predict(data_inputs)\n",
        "    mae = tensorflow.keras.losses.MeanAbsoluteError()\n",
        "    abs_error = mae(data_outputs, predictions).numpy() + 0.00000001\n",
        "    solution_fitness = 1.0/abs_error\n",
        "\n",
        "    return solution_fitness\n",
        "\n",
        "def callback_generation(ga_instance):\n",
        "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
        "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qypc3vN_7scp"
      },
      "source": [
        "# Create an instance of the pygad.kerasga.KerasGA class to build the initial population.\n",
        "keras_ga = pygad.kerasga.KerasGA(model=model,\n",
        "                                 num_solutions=100)\n",
        "\n",
        "# Data inputs\n",
        "data_inputs = train_features#numpy.load(\"dataset_inputs.npy\")\n",
        "\n",
        "# Data outputs\n",
        "data_outputs = train_labels#numpy.load(\"dataset_outputs.npy\")\n",
        "#data_outputs = tensorflow.keras.utils.to_categorical(data_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjoMkzuN76oR"
      },
      "source": [
        "# Prepare the PyGAD parameters. Check the documentation for more information: https://pygad.readthedocs.io/en/latest/README_pygad_ReadTheDocs.html#pygad-ga-class\n",
        "num_generations = 300 # Number of generations.\n",
        "num_parents_mating = 30 # Number of solutions to be selected as parents in the mating pool.\n",
        "initial_population = keras_ga.population_weights # Initial population of network weights\n",
        "parent_selection_type = \"sss\" # Type of parent selection.\n",
        "crossover_type = \"two_points\" # Type of the crossover operator.\n",
        "mutation_type = \"random\" # Type of the mutation operator.\n",
        "mutation_percent_genes = 10 # Percentage of genes to mutate. This parameter has no action if the parameter mutation_num_genes exists.\n",
        "keep_parents = 1 # Number of parents to keep in the next population. -1 means keep all parents and 0 means keep nothing.\n",
        "\n",
        "ga_instance = pygad.GA(num_generations=num_generations,\n",
        "                       num_parents_mating=num_parents_mating,\n",
        "                       initial_population=initial_population,\n",
        "                       fitness_func=fitness_func,\n",
        "                       parent_selection_type=parent_selection_type,\n",
        "                       crossover_type=crossover_type,\n",
        "                       mutation_type=mutation_type,\n",
        "                       mutation_percent_genes=mutation_percent_genes,\n",
        "                       keep_parents=keep_parents,\n",
        "                       on_generation=callback_generation)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4rL8rUA2UXn",
        "outputId": "465285a0-af17-4d90-b93c-a81133871422"
      },
      "source": [
        "# Start the genetic algorithm evolution.\n",
        "ga_instance.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generation = 1\n",
            "Fitness    = 0.027972601047977122\n",
            "Generation = 2\n",
            "Fitness    = 0.027972601047977122\n",
            "Generation = 3\n",
            "Fitness    = 0.08491719890487659\n",
            "Generation = 4\n",
            "Fitness    = 0.08491719890487659\n",
            "Generation = 5\n",
            "Fitness    = 0.08491719890487659\n",
            "Generation = 6\n",
            "Fitness    = 0.08491719890487659\n",
            "Generation = 7\n",
            "Fitness    = 0.08491719890487659\n",
            "Generation = 8\n",
            "Fitness    = 0.08491719890487659\n",
            "Generation = 9\n",
            "Fitness    = 0.08491719890487659\n",
            "Generation = 10\n",
            "Fitness    = 0.08491719890487659\n",
            "Generation = 11\n",
            "Fitness    = 0.09354745112770561\n",
            "Generation = 12\n",
            "Fitness    = 0.09354745112770561\n",
            "Generation = 13\n",
            "Fitness    = 0.09354745112770561\n",
            "Generation = 14\n",
            "Fitness    = 0.12834084253227304\n",
            "Generation = 15\n",
            "Fitness    = 0.12834084253227304\n",
            "Generation = 16\n",
            "Fitness    = 0.12834084253227304\n",
            "Generation = 17\n",
            "Fitness    = 0.12834084253227304\n",
            "Generation = 18\n",
            "Fitness    = 0.12834084253227304\n",
            "Generation = 19\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 20\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 21\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 22\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 23\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 24\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 25\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 26\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 27\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 28\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 29\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 30\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 31\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 32\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 33\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 34\n",
            "Fitness    = 0.12940447755702741\n",
            "Generation = 35\n",
            "Fitness    = 0.1350346072521476\n",
            "Generation = 36\n",
            "Fitness    = 0.14091084410395938\n",
            "Generation = 37\n",
            "Fitness    = 0.14860872047339957\n",
            "Generation = 38\n",
            "Fitness    = 0.15274508596672318\n",
            "Generation = 39\n",
            "Fitness    = 0.15584413629939223\n",
            "Generation = 40\n",
            "Fitness    = 0.1560988736705571\n",
            "Generation = 41\n",
            "Fitness    = 0.1560988736705571\n",
            "Generation = 42\n",
            "Fitness    = 0.1560988736705571\n",
            "Generation = 43\n",
            "Fitness    = 0.15610136018119228\n",
            "Generation = 44\n",
            "Fitness    = 0.15610136018119228\n",
            "Generation = 45\n",
            "Fitness    = 0.15610136018119228\n",
            "Generation = 46\n",
            "Fitness    = 0.15610136018119228\n",
            "Generation = 47\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 48\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 49\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 50\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 51\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 52\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 53\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 54\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 55\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 56\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 57\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 58\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 59\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 60\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 61\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 62\n",
            "Fitness    = 0.15610203410893397\n",
            "Generation = 63\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 64\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 65\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 66\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 67\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 68\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 69\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 70\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 71\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 72\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 73\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 74\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 75\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 76\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 77\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 78\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 79\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 80\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 81\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 82\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 83\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 84\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 85\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 86\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 87\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 88\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 89\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 90\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 91\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 92\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 93\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 94\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 95\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 96\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 97\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 98\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 99\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 100\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 101\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 102\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 103\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 104\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 105\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 106\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 107\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 108\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 109\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 110\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 111\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 112\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 113\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 114\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 115\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 116\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 117\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 118\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 119\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 120\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 121\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 122\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 123\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 124\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 125\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 126\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 127\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 128\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 129\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 130\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 131\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 132\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 133\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 134\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 135\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 136\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 137\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 138\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 139\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 140\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 141\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 142\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 143\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 144\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 145\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 146\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 147\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 148\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 149\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 150\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 151\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 152\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 153\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 154\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 155\n",
            "Fitness    = 0.1561022897382203\n",
            "Generation = 156\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 157\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 158\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 159\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 160\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 161\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 162\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 163\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 164\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 165\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 166\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 167\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 168\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 169\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 170\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 171\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 172\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 173\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 174\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 175\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 176\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 177\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 178\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 179\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 180\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 181\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 182\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 183\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 184\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 185\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 186\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 187\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 188\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 189\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 190\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 191\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 192\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 193\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 194\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 195\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 196\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 197\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 198\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 199\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 200\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 201\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 202\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 203\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 204\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 205\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 206\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 207\n",
            "Fitness    = 0.15610237107498698\n",
            "Generation = 208\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 209\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 210\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 211\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 212\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 213\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 214\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 215\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 216\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 217\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 218\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 219\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 220\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 221\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 222\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 223\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 224\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 225\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 226\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 227\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 228\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 229\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 230\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 231\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 232\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 233\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 234\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 235\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 236\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 237\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 238\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 239\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 240\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 241\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 242\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 243\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 244\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 245\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 246\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 247\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 248\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 249\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 250\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 251\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 252\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 253\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 254\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 255\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 256\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 257\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 258\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 259\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 260\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 261\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 262\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 263\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 264\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 265\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 266\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 267\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 268\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 269\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 270\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 271\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 272\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 273\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 274\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 275\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 276\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 277\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 278\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 279\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 280\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 281\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 282\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 283\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 284\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 285\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 286\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 287\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 288\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 289\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 290\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 291\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 292\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 293\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 294\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 295\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 296\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 297\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 298\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 299\n",
            "Fitness    = 0.1561024059336272\n",
            "Generation = 300\n",
            "Fitness    = 0.1561024059336272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRgfRCIM8AMD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "edb501d2-e437-4e52-9f94-b2620331c2e7"
      },
      "source": [
        "# After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.\n",
        "ga_instance.plot_result(title=\"PyGAD & Keras - Iteration vs. Fitness\", linewidth=4)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dUAEjLxXgKc",
        "outputId": "0e0977aa-8047-4d40-d0ea-fa49d9d6cad7"
      },
      "source": [
        "# Returning the details of the best solution.\n",
        "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
        "print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitness value of the best solution = 0.1561024059336272\n",
            "Index of the best solution : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVE5c2TaXj2_",
        "outputId": "e699833d-e4f0-4620-db36-8c2b08f616cf"
      },
      "source": [
        "# Fetch the parameters of the best solution.\n",
        "best_solution_weights = pygad.kerasga.model_weights_as_matrix(model=model,\n",
        "                                                              weights_vector=solution)\n",
        "model.set_weights(best_solution_weights)\n",
        "predictions = model.predict(data_inputs)\n",
        "print(\"Predictions : \\n\", predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions : \n",
            " [[22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]\n",
            " [22.000074]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih5655CAGQba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71504680-0b7e-489f-92c2-b61607eeca66"
      },
      "source": [
        "mae = tensorflow.keras.losses.MeanAbsoluteError()\n",
        "abs_error = mae(data_outputs, predictions).numpy()\n",
        "print(\"Absolute Error : \", abs_error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Absolute Error :  6.406051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlLB5F7PM3ID"
      },
      "source": [
        "# CMA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqQ0dNYJx7Sn"
      },
      "source": [
        "\n",
        "inputs=Input(shape=(9))\n",
        "dense_1=layers.Dense(16, activation='relu')(inputs)\n",
        "dense_2=layers.Dense(16, activation='relu')(dense_1)\n",
        "prediction=layers.Dense(1)(dense_2)\n",
        "\n",
        "modelEvol = EvolModel(inputs=inputs, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TFhMgyTPxFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d9aaad-5d93-4d45-b191-a6b290fd787a"
      },
      "source": [
        "myopt = evolutionary_keras.optimizers.CMA(population_size=5, sigma_init=15,max_evaluations=1500)\n",
        "modelEvol.compile(optimizer=myopt, loss=\"mean_absolute_error\", metrics=[\"accuracy\"])\n",
        "modelEvol.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"evol_model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 9)]               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 16)                160       \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 449\n",
            "Trainable params: 449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBQcJgNaP4NK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e361eb28-feb5-4669-c25f-92bb06d317d0"
      },
      "source": [
        "historyCMA = modelEvol.fit(\n",
        "    x=train_features,\n",
        "    y=train_labels,\n",
        "    epochs=1,\n",
        "    verbose=1,\n",
        "    #validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2_w,5mirr1)-aCMA-ES (mu_w=1.6,w_1=73%) in dimension 449 (seed=550637, Sat May  8 16:29:17 2021)\n",
            "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
            "    1      5 1.117872700000000e+07 1.0e+00 1.48e+01  1e+01  1e+01 0:00.5\n",
            "    2     10 4.569666000000000e+06 1.0e+00 1.46e+01  1e+01  1e+01 0:00.9\n",
            "    3     15 1.316577300000000e+07 1.0e+00 1.45e+01  1e+01  1e+01 0:01.3\n",
            "   12     60 3.229317800000000e+07 1.0e+00 1.32e+01  1e+01  1e+01 0:04.6\n",
            "   23    115 3.463318400000000e+08 1.0e+00 1.22e+01  1e+01  1e+01 0:08.7\n",
            "   37    185 2.478251680000000e+08 1.0e+00 1.13e+01  1e+01  1e+01 0:13.8\n",
            "   54    270 3.209941440000000e+08 1.0e+00 1.04e+01  1e+01  1e+01 0:20.1\n",
            "   73    365 3.429288640000000e+08 1.0e+00 9.64e+00  1e+01  1e+01 0:27.3\n",
            "   95    475 2.000695200000000e+08 1.0e+00 9.10e+00  9e+00  9e+00 0:35.3\n",
            "  120    600 3.864277760000000e+08 1.1e+00 8.69e+00  9e+00  9e+00 0:44.5\n",
            "  148    740 3.873723520000000e+08 1.1e+00 8.40e+00  8e+00  8e+00 0:54.8\n",
            "  178    890 4.032606400000000e+08 1.1e+00 8.24e+00  8e+00  8e+00 1:06.0\n",
            "  211   1055 7.017995520000000e+08 1.1e+00 8.12e+00  8e+00  8e+00 1:18.2\n",
            "  247   1235 5.311380160000000e+08 1.2e+00 8.08e+00  8e+00  8e+00 1:31.4\n",
            "  285   1425 7.209865600000000e+08 1.2e+00 8.17e+00  8e+00  8e+00 1:45.5\n",
            "  301   1505 1.386925440000000e+09 1.2e+00 8.23e+00  8e+00  8e+00 1:51.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:evolutionary_keras.models: > epoch: 1/1, 4569666.0 \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLbdsA78Zm4y",
        "outputId": "66546661-e2e7-41c0-bbd0-b98083fc904f"
      },
      "source": [
        "scoreCMA = modelEvol.evaluate(x=test_features, y=test_labels, return_dict=True, verbose=0)\n",
        "print(\"Test loss:\", scoreCMA['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1593269.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5JL657WP8ss"
      },
      "source": [
        "# NGA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niuO69GYvkRm"
      },
      "source": [
        "inputs=Input(shape=(9))\n",
        "dense_1=layers.Dense(16, activation='relu')(inputs)\n",
        "dense_2=layers.Dense(16, activation='relu')(dense_1)\n",
        "prediction=layers.Dense(1)(dense_2)\n",
        "\n",
        "modelEvol = EvolModel(inputs=inputs, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml86SpCEP-dm"
      },
      "source": [
        "#NGA\n",
        "myopt = evolutionary_keras.optimizers.NGA(population_size=5, sigma_init=15)\n",
        "modelEvol.compile(optimizer=myopt, loss=\"mean_absolute_error\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU0meJrTQAS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7ff355-a7c9-4188-c904-840d3fa2a504"
      },
      "source": [
        "historyNGA = modelEvol.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    verbose=1,\n",
        "    epochs=500\n",
        "    #validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:evolutionary_keras.models: > epoch: 1/500, 7.5232672691345215 \n",
            "INFO:evolutionary_keras.models: > epoch: 2/500, 7.5232672691345215 \n",
            "INFO:evolutionary_keras.models: > epoch: 3/500, 7.5232672691345215 \n",
            "INFO:evolutionary_keras.models: > epoch: 4/500, 7.5232672691345215 \n",
            "INFO:evolutionary_keras.models: > epoch: 5/500, 7.522800922393799 \n",
            "INFO:evolutionary_keras.models: > epoch: 6/500, 7.522800922393799 \n",
            "INFO:evolutionary_keras.models: > epoch: 7/500, 7.521057605743408 \n",
            "INFO:evolutionary_keras.models: > epoch: 8/500, 7.51942253112793 \n",
            "INFO:evolutionary_keras.models: > epoch: 9/500, 7.51942253112793 \n",
            "INFO:evolutionary_keras.models: > epoch: 10/500, 7.517667770385742 \n",
            "INFO:evolutionary_keras.models: > epoch: 11/500, 7.517667770385742 \n",
            "INFO:evolutionary_keras.models: > epoch: 12/500, 7.517427921295166 \n",
            "INFO:evolutionary_keras.models: > epoch: 13/500, 7.517427921295166 \n",
            "INFO:evolutionary_keras.models: > epoch: 14/500, 7.517205715179443 \n",
            "INFO:evolutionary_keras.models: > epoch: 15/500, 7.500038146972656 \n",
            "INFO:evolutionary_keras.models: > epoch: 16/500, 7.489246368408203 \n",
            "INFO:evolutionary_keras.models: > epoch: 17/500, 7.489246368408203 \n",
            "INFO:evolutionary_keras.models: > epoch: 18/500, 7.489246368408203 \n",
            "INFO:evolutionary_keras.models: > epoch: 19/500, 7.488168716430664 \n",
            "INFO:evolutionary_keras.models: > epoch: 20/500, 7.488168716430664 \n",
            "INFO:evolutionary_keras.models: > epoch: 21/500, 7.488027572631836 \n",
            "INFO:evolutionary_keras.models: > epoch: 22/500, 7.488027572631836 \n",
            "INFO:evolutionary_keras.models: > epoch: 23/500, 7.484026908874512 \n",
            "INFO:evolutionary_keras.models: > epoch: 24/500, 7.484026908874512 \n",
            "INFO:evolutionary_keras.models: > epoch: 25/500, 7.484026908874512 \n",
            "INFO:evolutionary_keras.models: > epoch: 26/500, 7.483984470367432 \n",
            "INFO:evolutionary_keras.models: > epoch: 27/500, 7.483984470367432 \n",
            "INFO:evolutionary_keras.models: > epoch: 28/500, 7.483984470367432 \n",
            "INFO:evolutionary_keras.models: > epoch: 29/500, 7.478229522705078 \n",
            "INFO:evolutionary_keras.models: > epoch: 30/500, 7.478229522705078 \n",
            "INFO:evolutionary_keras.models: > epoch: 31/500, 7.478229522705078 \n",
            "INFO:evolutionary_keras.models: > epoch: 32/500, 7.478229522705078 \n",
            "INFO:evolutionary_keras.models: > epoch: 33/500, 7.478229522705078 \n",
            "INFO:evolutionary_keras.models: > epoch: 34/500, 7.474431991577148 \n",
            "INFO:evolutionary_keras.models: > epoch: 35/500, 7.474175453186035 \n",
            "INFO:evolutionary_keras.models: > epoch: 36/500, 7.472613334655762 \n",
            "INFO:evolutionary_keras.models: > epoch: 37/500, 7.472613334655762 \n",
            "INFO:evolutionary_keras.models: > epoch: 38/500, 7.472613334655762 \n",
            "INFO:evolutionary_keras.models: > epoch: 39/500, 7.472613334655762 \n",
            "INFO:evolutionary_keras.models: > epoch: 40/500, 7.472613334655762 \n",
            "INFO:evolutionary_keras.models: > epoch: 41/500, 7.472613334655762 \n",
            "INFO:evolutionary_keras.models: > epoch: 42/500, 7.472613334655762 \n",
            "INFO:evolutionary_keras.models: > epoch: 43/500, 7.471994400024414 \n",
            "INFO:evolutionary_keras.models: > epoch: 44/500, 7.471994400024414 \n",
            "INFO:evolutionary_keras.models: > epoch: 45/500, 7.471947193145752 \n",
            "INFO:evolutionary_keras.models: > epoch: 46/500, 7.471947193145752 \n",
            "INFO:evolutionary_keras.models: > epoch: 47/500, 7.471555233001709 \n",
            "INFO:evolutionary_keras.models: > epoch: 48/500, 7.471555233001709 \n",
            "INFO:evolutionary_keras.models: > epoch: 49/500, 7.471555233001709 \n",
            "INFO:evolutionary_keras.models: > epoch: 50/500, 7.4715256690979 \n",
            "INFO:evolutionary_keras.models: > epoch: 51/500, 7.471500873565674 \n",
            "INFO:evolutionary_keras.models: > epoch: 52/500, 7.471500873565674 \n",
            "INFO:evolutionary_keras.models: > epoch: 53/500, 7.471500873565674 \n",
            "INFO:evolutionary_keras.models: > epoch: 54/500, 7.471500873565674 \n",
            "INFO:evolutionary_keras.models: > epoch: 55/500, 7.471500873565674 \n",
            "INFO:evolutionary_keras.models: > epoch: 56/500, 7.471500873565674 \n",
            "INFO:evolutionary_keras.models: > epoch: 57/500, 7.471500873565674 \n",
            "INFO:evolutionary_keras.models: > epoch: 58/500, 7.471500873565674 \n",
            "INFO:evolutionary_keras.models: > epoch: 59/500, 7.471418380737305 \n",
            "INFO:evolutionary_keras.models: > epoch: 60/500, 7.471418380737305 \n",
            "INFO:evolutionary_keras.models: > epoch: 61/500, 7.471311092376709 \n",
            "INFO:evolutionary_keras.models: > epoch: 62/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 63/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 64/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 65/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 66/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 67/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 68/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 69/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 70/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 71/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 72/500, 7.468670845031738 \n",
            "INFO:evolutionary_keras.models: > epoch: 73/500, 7.465972900390625 \n",
            "INFO:evolutionary_keras.models: > epoch: 74/500, 7.465972900390625 \n",
            "INFO:evolutionary_keras.models: > epoch: 75/500, 7.465972900390625 \n",
            "INFO:evolutionary_keras.models: > epoch: 76/500, 7.465764999389648 \n",
            "INFO:evolutionary_keras.models: > epoch: 77/500, 7.465764999389648 \n",
            "INFO:evolutionary_keras.models: > epoch: 78/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 79/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 80/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 81/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 82/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 83/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 84/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 85/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 86/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 87/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 88/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 89/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 90/500, 7.465335369110107 \n",
            "INFO:evolutionary_keras.models: > epoch: 91/500, 7.464501857757568 \n",
            "INFO:evolutionary_keras.models: > epoch: 92/500, 7.464493274688721 \n",
            "INFO:evolutionary_keras.models: > epoch: 93/500, 7.464493274688721 \n",
            "INFO:evolutionary_keras.models: > epoch: 94/500, 7.464493274688721 \n",
            "INFO:evolutionary_keras.models: > epoch: 95/500, 7.464493274688721 \n",
            "INFO:evolutionary_keras.models: > epoch: 96/500, 7.464010238647461 \n",
            "INFO:evolutionary_keras.models: > epoch: 97/500, 7.46146297454834 \n",
            "INFO:evolutionary_keras.models: > epoch: 98/500, 7.46146297454834 \n",
            "INFO:evolutionary_keras.models: > epoch: 99/500, 7.46146297454834 \n",
            "INFO:evolutionary_keras.models: > epoch: 100/500, 7.46146297454834 \n",
            "INFO:evolutionary_keras.models: > epoch: 101/500, 7.461438179016113 \n",
            "INFO:evolutionary_keras.models: > epoch: 102/500, 7.461438179016113 \n",
            "INFO:evolutionary_keras.models: > epoch: 103/500, 7.461438179016113 \n",
            "INFO:evolutionary_keras.models: > epoch: 104/500, 7.455175876617432 \n",
            "INFO:evolutionary_keras.models: > epoch: 105/500, 7.455175876617432 \n",
            "INFO:evolutionary_keras.models: > epoch: 106/500, 7.455175876617432 \n",
            "INFO:evolutionary_keras.models: > epoch: 107/500, 7.455175876617432 \n",
            "INFO:evolutionary_keras.models: > epoch: 108/500, 7.455175876617432 \n",
            "INFO:evolutionary_keras.models: > epoch: 109/500, 7.454736709594727 \n",
            "INFO:evolutionary_keras.models: > epoch: 110/500, 7.454736709594727 \n",
            "INFO:evolutionary_keras.models: > epoch: 111/500, 7.453655242919922 \n",
            "INFO:evolutionary_keras.models: > epoch: 112/500, 7.453655242919922 \n",
            "INFO:evolutionary_keras.models: > epoch: 113/500, 7.4535369873046875 \n",
            "INFO:evolutionary_keras.models: > epoch: 114/500, 7.4535369873046875 \n",
            "INFO:evolutionary_keras.models: > epoch: 115/500, 7.447507381439209 \n",
            "INFO:evolutionary_keras.models: > epoch: 116/500, 7.447507381439209 \n",
            "INFO:evolutionary_keras.models: > epoch: 117/500, 7.442863464355469 \n",
            "INFO:evolutionary_keras.models: > epoch: 118/500, 7.442863464355469 \n",
            "INFO:evolutionary_keras.models: > epoch: 119/500, 7.4425272941589355 \n",
            "INFO:evolutionary_keras.models: > epoch: 120/500, 7.442429542541504 \n",
            "INFO:evolutionary_keras.models: > epoch: 121/500, 7.442429542541504 \n",
            "INFO:evolutionary_keras.models: > epoch: 122/500, 7.441684722900391 \n",
            "INFO:evolutionary_keras.models: > epoch: 123/500, 7.441684722900391 \n",
            "INFO:evolutionary_keras.models: > epoch: 124/500, 7.441684722900391 \n",
            "INFO:evolutionary_keras.models: > epoch: 125/500, 7.441684722900391 \n",
            "INFO:evolutionary_keras.models: > epoch: 126/500, 7.441684722900391 \n",
            "INFO:evolutionary_keras.models: > epoch: 127/500, 7.441684722900391 \n",
            "INFO:evolutionary_keras.models: > epoch: 128/500, 7.4414777755737305 \n",
            "INFO:evolutionary_keras.models: > epoch: 129/500, 7.4414777755737305 \n",
            "INFO:evolutionary_keras.models: > epoch: 130/500, 7.438715934753418 \n",
            "INFO:evolutionary_keras.models: > epoch: 131/500, 7.430263042449951 \n",
            "INFO:evolutionary_keras.models: > epoch: 132/500, 7.430263042449951 \n",
            "INFO:evolutionary_keras.models: > epoch: 133/500, 7.430263042449951 \n",
            "INFO:evolutionary_keras.models: > epoch: 134/500, 7.430263042449951 \n",
            "INFO:evolutionary_keras.models: > epoch: 135/500, 7.429961204528809 \n",
            "INFO:evolutionary_keras.models: > epoch: 136/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 137/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 138/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 139/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 140/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 141/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 142/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 143/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 144/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 145/500, 7.427673816680908 \n",
            "INFO:evolutionary_keras.models: > epoch: 146/500, 7.402829647064209 \n",
            "INFO:evolutionary_keras.models: > epoch: 147/500, 7.402829647064209 \n",
            "INFO:evolutionary_keras.models: > epoch: 148/500, 7.402829647064209 \n",
            "INFO:evolutionary_keras.models: > epoch: 149/500, 7.400382041931152 \n",
            "INFO:evolutionary_keras.models: > epoch: 150/500, 7.400382041931152 \n",
            "INFO:evolutionary_keras.models: > epoch: 151/500, 7.400382041931152 \n",
            "INFO:evolutionary_keras.models: > epoch: 152/500, 7.400382041931152 \n",
            "INFO:evolutionary_keras.models: > epoch: 153/500, 7.400382041931152 \n",
            "INFO:evolutionary_keras.models: > epoch: 154/500, 7.398299694061279 \n",
            "INFO:evolutionary_keras.models: > epoch: 155/500, 7.397810935974121 \n",
            "INFO:evolutionary_keras.models: > epoch: 156/500, 7.397810935974121 \n",
            "INFO:evolutionary_keras.models: > epoch: 157/500, 7.397810935974121 \n",
            "INFO:evolutionary_keras.models: > epoch: 158/500, 7.397810935974121 \n",
            "INFO:evolutionary_keras.models: > epoch: 159/500, 7.378921985626221 \n",
            "INFO:evolutionary_keras.models: > epoch: 160/500, 7.378854274749756 \n",
            "INFO:evolutionary_keras.models: > epoch: 161/500, 7.378854274749756 \n",
            "INFO:evolutionary_keras.models: > epoch: 162/500, 7.378854274749756 \n",
            "INFO:evolutionary_keras.models: > epoch: 163/500, 7.378854274749756 \n",
            "INFO:evolutionary_keras.models: > epoch: 164/500, 7.37835168838501 \n",
            "INFO:evolutionary_keras.models: > epoch: 165/500, 7.37835168838501 \n",
            "INFO:evolutionary_keras.models: > epoch: 166/500, 7.378204822540283 \n",
            "INFO:evolutionary_keras.models: > epoch: 167/500, 7.3781962394714355 \n",
            "INFO:evolutionary_keras.models: > epoch: 168/500, 7.3781962394714355 \n",
            "INFO:evolutionary_keras.models: > epoch: 169/500, 7.374547481536865 \n",
            "INFO:evolutionary_keras.models: > epoch: 170/500, 7.374460220336914 \n",
            "INFO:evolutionary_keras.models: > epoch: 171/500, 7.374420166015625 \n",
            "INFO:evolutionary_keras.models: > epoch: 172/500, 7.373989105224609 \n",
            "INFO:evolutionary_keras.models: > epoch: 173/500, 7.373989105224609 \n",
            "INFO:evolutionary_keras.models: > epoch: 174/500, 7.373989105224609 \n",
            "INFO:evolutionary_keras.models: > epoch: 175/500, 7.373989105224609 \n",
            "INFO:evolutionary_keras.models: > epoch: 176/500, 7.373989105224609 \n",
            "INFO:evolutionary_keras.models: > epoch: 177/500, 7.373989105224609 \n",
            "INFO:evolutionary_keras.models: > epoch: 178/500, 7.373989105224609 \n",
            "INFO:evolutionary_keras.models: > epoch: 179/500, 7.372854709625244 \n",
            "INFO:evolutionary_keras.models: > epoch: 180/500, 7.372854709625244 \n",
            "INFO:evolutionary_keras.models: > epoch: 181/500, 7.372854709625244 \n",
            "INFO:evolutionary_keras.models: > epoch: 182/500, 7.372854709625244 \n",
            "INFO:evolutionary_keras.models: > epoch: 183/500, 7.372854709625244 \n",
            "INFO:evolutionary_keras.models: > epoch: 184/500, 7.372854709625244 \n",
            "INFO:evolutionary_keras.models: > epoch: 185/500, 7.372763633728027 \n",
            "INFO:evolutionary_keras.models: > epoch: 186/500, 7.372763633728027 \n",
            "INFO:evolutionary_keras.models: > epoch: 187/500, 7.372763633728027 \n",
            "INFO:evolutionary_keras.models: > epoch: 188/500, 7.371837615966797 \n",
            "INFO:evolutionary_keras.models: > epoch: 189/500, 7.371837615966797 \n",
            "INFO:evolutionary_keras.models: > epoch: 190/500, 7.371837615966797 \n",
            "INFO:evolutionary_keras.models: > epoch: 191/500, 7.371837615966797 \n",
            "INFO:evolutionary_keras.models: > epoch: 192/500, 7.371837615966797 \n",
            "INFO:evolutionary_keras.models: > epoch: 193/500, 7.371490478515625 \n",
            "INFO:evolutionary_keras.models: > epoch: 194/500, 7.370541095733643 \n",
            "INFO:evolutionary_keras.models: > epoch: 195/500, 7.370541095733643 \n",
            "INFO:evolutionary_keras.models: > epoch: 196/500, 7.370541095733643 \n",
            "INFO:evolutionary_keras.models: > epoch: 197/500, 7.370541095733643 \n",
            "INFO:evolutionary_keras.models: > epoch: 198/500, 7.370537281036377 \n",
            "INFO:evolutionary_keras.models: > epoch: 199/500, 7.370537281036377 \n",
            "INFO:evolutionary_keras.models: > epoch: 200/500, 7.370537281036377 \n",
            "INFO:evolutionary_keras.models: > epoch: 201/500, 7.370358943939209 \n",
            "INFO:evolutionary_keras.models: > epoch: 202/500, 7.370358943939209 \n",
            "INFO:evolutionary_keras.models: > epoch: 203/500, 7.370358943939209 \n",
            "INFO:evolutionary_keras.models: > epoch: 204/500, 7.370358943939209 \n",
            "INFO:evolutionary_keras.models: > epoch: 205/500, 7.370358943939209 \n",
            "INFO:evolutionary_keras.models: > epoch: 206/500, 7.370358943939209 \n",
            "INFO:evolutionary_keras.models: > epoch: 207/500, 7.370358943939209 \n",
            "INFO:evolutionary_keras.models: > epoch: 208/500, 7.370358943939209 \n",
            "INFO:evolutionary_keras.models: > epoch: 209/500, 7.370358943939209 \n",
            "INFO:evolutionary_keras.models: > epoch: 210/500, 7.368499755859375 \n",
            "INFO:evolutionary_keras.models: > epoch: 211/500, 7.354153156280518 \n",
            "INFO:evolutionary_keras.models: > epoch: 212/500, 7.350665092468262 \n",
            "INFO:evolutionary_keras.models: > epoch: 213/500, 7.339648723602295 \n",
            "INFO:evolutionary_keras.models: > epoch: 214/500, 7.339648723602295 \n",
            "INFO:evolutionary_keras.models: > epoch: 215/500, 7.339648723602295 \n",
            "INFO:evolutionary_keras.models: > epoch: 216/500, 7.339648723602295 \n",
            "INFO:evolutionary_keras.models: > epoch: 217/500, 7.265779495239258 \n",
            "INFO:evolutionary_keras.models: > epoch: 218/500, 7.265779495239258 \n",
            "INFO:evolutionary_keras.models: > epoch: 219/500, 7.265779495239258 \n",
            "INFO:evolutionary_keras.models: > epoch: 220/500, 7.265779495239258 \n",
            "INFO:evolutionary_keras.models: > epoch: 221/500, 7.265765190124512 \n",
            "INFO:evolutionary_keras.models: > epoch: 222/500, 7.265045166015625 \n",
            "INFO:evolutionary_keras.models: > epoch: 223/500, 7.265045166015625 \n",
            "INFO:evolutionary_keras.models: > epoch: 224/500, 7.265045166015625 \n",
            "INFO:evolutionary_keras.models: > epoch: 225/500, 7.265045166015625 \n",
            "INFO:evolutionary_keras.models: > epoch: 226/500, 7.265045166015625 \n",
            "INFO:evolutionary_keras.models: > epoch: 227/500, 7.265045166015625 \n",
            "INFO:evolutionary_keras.models: > epoch: 228/500, 7.262548446655273 \n",
            "INFO:evolutionary_keras.models: > epoch: 229/500, 7.262548446655273 \n",
            "INFO:evolutionary_keras.models: > epoch: 230/500, 7.262548446655273 \n",
            "INFO:evolutionary_keras.models: > epoch: 231/500, 7.261924743652344 \n",
            "INFO:evolutionary_keras.models: > epoch: 232/500, 7.261924743652344 \n",
            "INFO:evolutionary_keras.models: > epoch: 233/500, 7.261924743652344 \n",
            "INFO:evolutionary_keras.models: > epoch: 234/500, 7.261924743652344 \n",
            "INFO:evolutionary_keras.models: > epoch: 235/500, 7.2608113288879395 \n",
            "INFO:evolutionary_keras.models: > epoch: 236/500, 7.2608113288879395 \n",
            "INFO:evolutionary_keras.models: > epoch: 237/500, 7.2608113288879395 \n",
            "INFO:evolutionary_keras.models: > epoch: 238/500, 7.2608113288879395 \n",
            "INFO:evolutionary_keras.models: > epoch: 239/500, 7.259658336639404 \n",
            "INFO:evolutionary_keras.models: > epoch: 240/500, 7.259658336639404 \n",
            "INFO:evolutionary_keras.models: > epoch: 241/500, 7.259658336639404 \n",
            "INFO:evolutionary_keras.models: > epoch: 242/500, 7.259658336639404 \n",
            "INFO:evolutionary_keras.models: > epoch: 243/500, 7.259658336639404 \n",
            "INFO:evolutionary_keras.models: > epoch: 244/500, 7.258076190948486 \n",
            "INFO:evolutionary_keras.models: > epoch: 245/500, 7.258076190948486 \n",
            "INFO:evolutionary_keras.models: > epoch: 246/500, 7.258076190948486 \n",
            "INFO:evolutionary_keras.models: > epoch: 247/500, 7.258076190948486 \n",
            "INFO:evolutionary_keras.models: > epoch: 248/500, 7.258076190948486 \n",
            "INFO:evolutionary_keras.models: > epoch: 249/500, 7.258076190948486 \n",
            "INFO:evolutionary_keras.models: > epoch: 250/500, 7.25758171081543 \n",
            "INFO:evolutionary_keras.models: > epoch: 251/500, 7.25758171081543 \n",
            "INFO:evolutionary_keras.models: > epoch: 252/500, 7.25758171081543 \n",
            "INFO:evolutionary_keras.models: > epoch: 253/500, 7.25758171081543 \n",
            "INFO:evolutionary_keras.models: > epoch: 254/500, 7.25758171081543 \n",
            "INFO:evolutionary_keras.models: > epoch: 255/500, 7.256155490875244 \n",
            "INFO:evolutionary_keras.models: > epoch: 256/500, 7.255087375640869 \n",
            "INFO:evolutionary_keras.models: > epoch: 257/500, 7.255087375640869 \n",
            "INFO:evolutionary_keras.models: > epoch: 258/500, 7.255087375640869 \n",
            "INFO:evolutionary_keras.models: > epoch: 259/500, 7.255087375640869 \n",
            "INFO:evolutionary_keras.models: > epoch: 260/500, 7.255087375640869 \n",
            "INFO:evolutionary_keras.models: > epoch: 261/500, 7.2540974617004395 \n",
            "INFO:evolutionary_keras.models: > epoch: 262/500, 7.2540974617004395 \n",
            "INFO:evolutionary_keras.models: > epoch: 263/500, 7.2540974617004395 \n",
            "INFO:evolutionary_keras.models: > epoch: 264/500, 7.2535719871521 \n",
            "INFO:evolutionary_keras.models: > epoch: 265/500, 7.2535719871521 \n",
            "INFO:evolutionary_keras.models: > epoch: 266/500, 7.2535719871521 \n",
            "INFO:evolutionary_keras.models: > epoch: 267/500, 7.2535719871521 \n",
            "INFO:evolutionary_keras.models: > epoch: 268/500, 7.2535719871521 \n",
            "INFO:evolutionary_keras.models: > epoch: 269/500, 7.2535719871521 \n",
            "INFO:evolutionary_keras.models: > epoch: 270/500, 7.2535719871521 \n",
            "INFO:evolutionary_keras.models: > epoch: 271/500, 7.245304584503174 \n",
            "INFO:evolutionary_keras.models: > epoch: 272/500, 7.238332748413086 \n",
            "INFO:evolutionary_keras.models: > epoch: 273/500, 7.238332748413086 \n",
            "INFO:evolutionary_keras.models: > epoch: 274/500, 7.237954139709473 \n",
            "INFO:evolutionary_keras.models: > epoch: 275/500, 7.23790979385376 \n",
            "INFO:evolutionary_keras.models: > epoch: 276/500, 7.23790979385376 \n",
            "INFO:evolutionary_keras.models: > epoch: 277/500, 7.23790979385376 \n",
            "INFO:evolutionary_keras.models: > epoch: 278/500, 7.23790979385376 \n",
            "INFO:evolutionary_keras.models: > epoch: 279/500, 7.237547397613525 \n",
            "INFO:evolutionary_keras.models: > epoch: 280/500, 7.237547397613525 \n",
            "INFO:evolutionary_keras.models: > epoch: 281/500, 7.237547397613525 \n",
            "INFO:evolutionary_keras.models: > epoch: 282/500, 7.237272262573242 \n",
            "INFO:evolutionary_keras.models: > epoch: 283/500, 7.23723840713501 \n",
            "INFO:evolutionary_keras.models: > epoch: 284/500, 7.23723840713501 \n",
            "INFO:evolutionary_keras.models: > epoch: 285/500, 7.23723840713501 \n",
            "INFO:evolutionary_keras.models: > epoch: 286/500, 7.23723840713501 \n",
            "INFO:evolutionary_keras.models: > epoch: 287/500, 7.2367448806762695 \n",
            "INFO:evolutionary_keras.models: > epoch: 288/500, 7.2367448806762695 \n",
            "INFO:evolutionary_keras.models: > epoch: 289/500, 7.2367448806762695 \n",
            "INFO:evolutionary_keras.models: > epoch: 290/500, 7.236512184143066 \n",
            "INFO:evolutionary_keras.models: > epoch: 291/500, 7.236512184143066 \n",
            "INFO:evolutionary_keras.models: > epoch: 292/500, 7.236512184143066 \n",
            "INFO:evolutionary_keras.models: > epoch: 293/500, 7.236512184143066 \n",
            "INFO:evolutionary_keras.models: > epoch: 294/500, 7.236512184143066 \n",
            "INFO:evolutionary_keras.models: > epoch: 295/500, 7.236043453216553 \n",
            "INFO:evolutionary_keras.models: > epoch: 296/500, 7.236043453216553 \n",
            "INFO:evolutionary_keras.models: > epoch: 297/500, 7.236043453216553 \n",
            "INFO:evolutionary_keras.models: > epoch: 298/500, 7.235769748687744 \n",
            "INFO:evolutionary_keras.models: > epoch: 299/500, 7.235281467437744 \n",
            "INFO:evolutionary_keras.models: > epoch: 300/500, 7.235281467437744 \n",
            "INFO:evolutionary_keras.models: > epoch: 301/500, 7.235256671905518 \n",
            "INFO:evolutionary_keras.models: > epoch: 302/500, 7.235256671905518 \n",
            "INFO:evolutionary_keras.models: > epoch: 303/500, 7.23465633392334 \n",
            "INFO:evolutionary_keras.models: > epoch: 304/500, 7.234413146972656 \n",
            "INFO:evolutionary_keras.models: > epoch: 305/500, 7.232012748718262 \n",
            "INFO:evolutionary_keras.models: > epoch: 306/500, 7.232012748718262 \n",
            "INFO:evolutionary_keras.models: > epoch: 307/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 308/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 309/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 310/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 311/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 312/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 313/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 314/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 315/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 316/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 317/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 318/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 319/500, 7.231658458709717 \n",
            "INFO:evolutionary_keras.models: > epoch: 320/500, 7.23096227645874 \n",
            "INFO:evolutionary_keras.models: > epoch: 321/500, 7.23096227645874 \n",
            "INFO:evolutionary_keras.models: > epoch: 322/500, 7.23096227645874 \n",
            "INFO:evolutionary_keras.models: > epoch: 323/500, 7.23096227645874 \n",
            "INFO:evolutionary_keras.models: > epoch: 324/500, 7.230411052703857 \n",
            "INFO:evolutionary_keras.models: > epoch: 325/500, 7.230411052703857 \n",
            "INFO:evolutionary_keras.models: > epoch: 326/500, 7.230411052703857 \n",
            "INFO:evolutionary_keras.models: > epoch: 327/500, 7.230411052703857 \n",
            "INFO:evolutionary_keras.models: > epoch: 328/500, 7.230411052703857 \n",
            "INFO:evolutionary_keras.models: > epoch: 329/500, 7.229617595672607 \n",
            "INFO:evolutionary_keras.models: > epoch: 330/500, 7.229527950286865 \n",
            "INFO:evolutionary_keras.models: > epoch: 331/500, 7.229520320892334 \n",
            "INFO:evolutionary_keras.models: > epoch: 332/500, 7.229520320892334 \n",
            "INFO:evolutionary_keras.models: > epoch: 333/500, 7.226792812347412 \n",
            "INFO:evolutionary_keras.models: > epoch: 334/500, 7.226792812347412 \n",
            "INFO:evolutionary_keras.models: > epoch: 335/500, 7.226792812347412 \n",
            "INFO:evolutionary_keras.models: > epoch: 336/500, 7.225578308105469 \n",
            "INFO:evolutionary_keras.models: > epoch: 337/500, 7.225521564483643 \n",
            "INFO:evolutionary_keras.models: > epoch: 338/500, 7.224837779998779 \n",
            "INFO:evolutionary_keras.models: > epoch: 339/500, 7.224833965301514 \n",
            "INFO:evolutionary_keras.models: > epoch: 340/500, 7.224833965301514 \n",
            "INFO:evolutionary_keras.models: > epoch: 341/500, 7.224833965301514 \n",
            "INFO:evolutionary_keras.models: > epoch: 342/500, 7.224833965301514 \n",
            "INFO:evolutionary_keras.models: > epoch: 343/500, 7.224833965301514 \n",
            "INFO:evolutionary_keras.models: > epoch: 344/500, 7.224833965301514 \n",
            "INFO:evolutionary_keras.models: > epoch: 345/500, 7.224833965301514 \n",
            "INFO:evolutionary_keras.models: > epoch: 346/500, 7.224735260009766 \n",
            "INFO:evolutionary_keras.models: > epoch: 347/500, 7.224735260009766 \n",
            "INFO:evolutionary_keras.models: > epoch: 348/500, 7.224735260009766 \n",
            "INFO:evolutionary_keras.models: > epoch: 349/500, 7.224735260009766 \n",
            "INFO:evolutionary_keras.models: > epoch: 350/500, 7.224735260009766 \n",
            "INFO:evolutionary_keras.models: > epoch: 351/500, 7.224735260009766 \n",
            "INFO:evolutionary_keras.models: > epoch: 352/500, 7.224735260009766 \n",
            "INFO:evolutionary_keras.models: > epoch: 353/500, 7.224735260009766 \n",
            "INFO:evolutionary_keras.models: > epoch: 354/500, 7.224617004394531 \n",
            "INFO:evolutionary_keras.models: > epoch: 355/500, 7.224617004394531 \n",
            "INFO:evolutionary_keras.models: > epoch: 356/500, 7.224595546722412 \n",
            "INFO:evolutionary_keras.models: > epoch: 357/500, 7.224576950073242 \n",
            "INFO:evolutionary_keras.models: > epoch: 358/500, 7.224576950073242 \n",
            "INFO:evolutionary_keras.models: > epoch: 359/500, 7.224576950073242 \n",
            "INFO:evolutionary_keras.models: > epoch: 360/500, 7.224508285522461 \n",
            "INFO:evolutionary_keras.models: > epoch: 361/500, 7.224108695983887 \n",
            "INFO:evolutionary_keras.models: > epoch: 362/500, 7.224108695983887 \n",
            "INFO:evolutionary_keras.models: > epoch: 363/500, 7.224108695983887 \n",
            "INFO:evolutionary_keras.models: > epoch: 364/500, 7.224108695983887 \n",
            "INFO:evolutionary_keras.models: > epoch: 365/500, 7.224108695983887 \n",
            "INFO:evolutionary_keras.models: > epoch: 366/500, 7.223983287811279 \n",
            "INFO:evolutionary_keras.models: > epoch: 367/500, 7.223983287811279 \n",
            "INFO:evolutionary_keras.models: > epoch: 368/500, 7.223983287811279 \n",
            "INFO:evolutionary_keras.models: > epoch: 369/500, 7.223983287811279 \n",
            "INFO:evolutionary_keras.models: > epoch: 370/500, 7.22388219833374 \n",
            "INFO:evolutionary_keras.models: > epoch: 371/500, 7.22388219833374 \n",
            "INFO:evolutionary_keras.models: > epoch: 372/500, 7.223793983459473 \n",
            "INFO:evolutionary_keras.models: > epoch: 373/500, 7.223793983459473 \n",
            "INFO:evolutionary_keras.models: > epoch: 374/500, 7.223790645599365 \n",
            "INFO:evolutionary_keras.models: > epoch: 375/500, 7.223790645599365 \n",
            "INFO:evolutionary_keras.models: > epoch: 376/500, 7.223790645599365 \n",
            "INFO:evolutionary_keras.models: > epoch: 377/500, 7.223620414733887 \n",
            "INFO:evolutionary_keras.models: > epoch: 378/500, 7.223620414733887 \n",
            "INFO:evolutionary_keras.models: > epoch: 379/500, 7.223438262939453 \n",
            "INFO:evolutionary_keras.models: > epoch: 380/500, 7.2233662605285645 \n",
            "INFO:evolutionary_keras.models: > epoch: 381/500, 7.2233662605285645 \n",
            "INFO:evolutionary_keras.models: > epoch: 382/500, 7.223316192626953 \n",
            "INFO:evolutionary_keras.models: > epoch: 383/500, 7.223316192626953 \n",
            "INFO:evolutionary_keras.models: > epoch: 384/500, 7.223316192626953 \n",
            "INFO:evolutionary_keras.models: > epoch: 385/500, 7.223316192626953 \n",
            "INFO:evolutionary_keras.models: > epoch: 386/500, 7.223316192626953 \n",
            "INFO:evolutionary_keras.models: > epoch: 387/500, 7.223316192626953 \n",
            "INFO:evolutionary_keras.models: > epoch: 388/500, 7.223316192626953 \n",
            "INFO:evolutionary_keras.models: > epoch: 389/500, 7.22303581237793 \n",
            "INFO:evolutionary_keras.models: > epoch: 390/500, 7.22303581237793 \n",
            "INFO:evolutionary_keras.models: > epoch: 391/500, 7.22303581237793 \n",
            "INFO:evolutionary_keras.models: > epoch: 392/500, 7.2226104736328125 \n",
            "INFO:evolutionary_keras.models: > epoch: 393/500, 7.2226104736328125 \n",
            "INFO:evolutionary_keras.models: > epoch: 394/500, 7.2226104736328125 \n",
            "INFO:evolutionary_keras.models: > epoch: 395/500, 7.2226104736328125 \n",
            "INFO:evolutionary_keras.models: > epoch: 396/500, 7.2201151847839355 \n",
            "INFO:evolutionary_keras.models: > epoch: 397/500, 7.2201151847839355 \n",
            "INFO:evolutionary_keras.models: > epoch: 398/500, 7.2201151847839355 \n",
            "INFO:evolutionary_keras.models: > epoch: 399/500, 7.2201151847839355 \n",
            "INFO:evolutionary_keras.models: > epoch: 400/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 401/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 402/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 403/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 404/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 405/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 406/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 407/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 408/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 409/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 410/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 411/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 412/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 413/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 414/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 415/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 416/500, 7.220026016235352 \n",
            "INFO:evolutionary_keras.models: > epoch: 417/500, 7.219988822937012 \n",
            "INFO:evolutionary_keras.models: > epoch: 418/500, 7.219988822937012 \n",
            "INFO:evolutionary_keras.models: > epoch: 419/500, 7.219988822937012 \n",
            "INFO:evolutionary_keras.models: > epoch: 420/500, 7.218967914581299 \n",
            "INFO:evolutionary_keras.models: > epoch: 421/500, 7.218967914581299 \n",
            "INFO:evolutionary_keras.models: > epoch: 422/500, 7.218967914581299 \n",
            "INFO:evolutionary_keras.models: > epoch: 423/500, 7.218869686126709 \n",
            "INFO:evolutionary_keras.models: > epoch: 424/500, 7.218869686126709 \n",
            "INFO:evolutionary_keras.models: > epoch: 425/500, 7.218869686126709 \n",
            "INFO:evolutionary_keras.models: > epoch: 426/500, 7.218869686126709 \n",
            "INFO:evolutionary_keras.models: > epoch: 427/500, 7.218869686126709 \n",
            "INFO:evolutionary_keras.models: > epoch: 428/500, 7.218869686126709 \n",
            "INFO:evolutionary_keras.models: > epoch: 429/500, 7.218869686126709 \n",
            "INFO:evolutionary_keras.models: > epoch: 430/500, 7.218869686126709 \n",
            "INFO:evolutionary_keras.models: > epoch: 431/500, 7.218869686126709 \n",
            "INFO:evolutionary_keras.models: > epoch: 432/500, 7.21883487701416 \n",
            "INFO:evolutionary_keras.models: > epoch: 433/500, 7.21883487701416 \n",
            "INFO:evolutionary_keras.models: > epoch: 434/500, 7.21883487701416 \n",
            "INFO:evolutionary_keras.models: > epoch: 435/500, 7.218662261962891 \n",
            "INFO:evolutionary_keras.models: > epoch: 436/500, 7.218662261962891 \n",
            "INFO:evolutionary_keras.models: > epoch: 437/500, 7.218662261962891 \n",
            "INFO:evolutionary_keras.models: > epoch: 438/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 439/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 440/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 441/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 442/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 443/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 444/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 445/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 446/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 447/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 448/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 449/500, 7.218518257141113 \n",
            "INFO:evolutionary_keras.models: > epoch: 450/500, 7.218118667602539 \n",
            "INFO:evolutionary_keras.models: > epoch: 451/500, 7.218118667602539 \n",
            "INFO:evolutionary_keras.models: > epoch: 452/500, 7.218050003051758 \n",
            "INFO:evolutionary_keras.models: > epoch: 453/500, 7.218050003051758 \n",
            "INFO:evolutionary_keras.models: > epoch: 454/500, 7.218050003051758 \n",
            "INFO:evolutionary_keras.models: > epoch: 455/500, 7.218050003051758 \n",
            "INFO:evolutionary_keras.models: > epoch: 456/500, 7.217953681945801 \n",
            "INFO:evolutionary_keras.models: > epoch: 457/500, 7.217848300933838 \n",
            "INFO:evolutionary_keras.models: > epoch: 458/500, 7.217848300933838 \n",
            "INFO:evolutionary_keras.models: > epoch: 459/500, 7.217848300933838 \n",
            "INFO:evolutionary_keras.models: > epoch: 460/500, 7.217611789703369 \n",
            "INFO:evolutionary_keras.models: > epoch: 461/500, 7.2170186042785645 \n",
            "INFO:evolutionary_keras.models: > epoch: 462/500, 7.2170186042785645 \n",
            "INFO:evolutionary_keras.models: > epoch: 463/500, 7.2170186042785645 \n",
            "INFO:evolutionary_keras.models: > epoch: 464/500, 7.2170186042785645 \n",
            "INFO:evolutionary_keras.models: > epoch: 465/500, 7.2170186042785645 \n",
            "INFO:evolutionary_keras.models: > epoch: 466/500, 7.216731548309326 \n",
            "INFO:evolutionary_keras.models: > epoch: 467/500, 7.216731548309326 \n",
            "INFO:evolutionary_keras.models: > epoch: 468/500, 7.216731548309326 \n",
            "INFO:evolutionary_keras.models: > epoch: 469/500, 7.2156662940979 \n",
            "INFO:evolutionary_keras.models: > epoch: 470/500, 7.2156662940979 \n",
            "INFO:evolutionary_keras.models: > epoch: 471/500, 7.2156662940979 \n",
            "INFO:evolutionary_keras.models: > epoch: 472/500, 7.215652942657471 \n",
            "INFO:evolutionary_keras.models: > epoch: 473/500, 7.215652942657471 \n",
            "INFO:evolutionary_keras.models: > epoch: 474/500, 7.215324878692627 \n",
            "INFO:evolutionary_keras.models: > epoch: 475/500, 7.215324878692627 \n",
            "INFO:evolutionary_keras.models: > epoch: 476/500, 7.215324878692627 \n",
            "INFO:evolutionary_keras.models: > epoch: 477/500, 7.215324878692627 \n",
            "INFO:evolutionary_keras.models: > epoch: 478/500, 7.215324878692627 \n",
            "INFO:evolutionary_keras.models: > epoch: 479/500, 7.215324878692627 \n",
            "INFO:evolutionary_keras.models: > epoch: 480/500, 7.215188980102539 \n",
            "INFO:evolutionary_keras.models: > epoch: 481/500, 7.215188980102539 \n",
            "INFO:evolutionary_keras.models: > epoch: 482/500, 7.215188980102539 \n",
            "INFO:evolutionary_keras.models: > epoch: 483/500, 7.215188980102539 \n",
            "INFO:evolutionary_keras.models: > epoch: 484/500, 7.215188980102539 \n",
            "INFO:evolutionary_keras.models: > epoch: 485/500, 7.215188980102539 \n",
            "INFO:evolutionary_keras.models: > epoch: 486/500, 7.215188980102539 \n",
            "INFO:evolutionary_keras.models: > epoch: 487/500, 7.215188980102539 \n",
            "INFO:evolutionary_keras.models: > epoch: 488/500, 7.215151786804199 \n",
            "INFO:evolutionary_keras.models: > epoch: 489/500, 7.215151786804199 \n",
            "INFO:evolutionary_keras.models: > epoch: 490/500, 7.215151786804199 \n",
            "INFO:evolutionary_keras.models: > epoch: 491/500, 7.215151786804199 \n",
            "INFO:evolutionary_keras.models: > epoch: 492/500, 7.215151786804199 \n",
            "INFO:evolutionary_keras.models: > epoch: 493/500, 7.215151786804199 \n",
            "INFO:evolutionary_keras.models: > epoch: 494/500, 7.214766025543213 \n",
            "INFO:evolutionary_keras.models: > epoch: 495/500, 7.214766025543213 \n",
            "INFO:evolutionary_keras.models: > epoch: 496/500, 7.214766025543213 \n",
            "INFO:evolutionary_keras.models: > epoch: 497/500, 7.214766025543213 \n",
            "INFO:evolutionary_keras.models: > epoch: 498/500, 7.214766025543213 \n",
            "INFO:evolutionary_keras.models: > epoch: 499/500, 7.214552879333496 \n",
            "INFO:evolutionary_keras.models: > epoch: 500/500, 7.214552879333496 \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyA3_-R8QBZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708ba885-6717-4ce9-8685-773894406971"
      },
      "source": [
        "scoreNGA= modelEvol.evaluate(x=test_features, y=test_labels, return_dict=True, verbose=0)\n",
        "print(\"Test loss:\", scoreNGA['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 8.258469581604004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "zYOoYAgUv4n_",
        "outputId": "ca85a84a-4f69-48b6-f443-28180bc0216e"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(range(len(historyGD.history['loss'])), historyGD.history['loss'], label='Gradient Descent')\n",
        "plt.plot(range(len(historyNGA.history['loss'])), historyNGA.history['loss'],label='NGA')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}